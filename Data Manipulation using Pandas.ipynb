{
 "cells": [
  {
   "attachments": {
    "pandas.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation using Pandas\n",
    "\n",
    "\n",
    "\n",
    "![pandas.png](attachment:pandas.png)\n",
    "\n",
    "Pandas is a Python library that provides powerful, flexible and high-performance tools for data processing. It was created by Wes McKinney in 2008.\n",
    "\n",
    "\n",
    "The following are some of its key features:\n",
    "* Provides high-performance DataFrame objects with effective indexing.\n",
    "* Provides tools for loading data into memory with multiple file formats.\n",
    "* Provides high performance for operations such as data merges and joins.\n",
    "* Provides support for manipulating time series data.\n",
    "* Row and column data can be easily manipulated.\n",
    "* SQL-like operations are supported.\n",
    "* Vectorized operations are supported.\n",
    "* Large data sets can be sliced, indexed, and subset based on their label.\n",
    "\n",
    "\n",
    "In this  blog post we are going to learn about different data manipulation using pandas \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Sorting a DataFrame\n",
    "Pandas allow you to sort data in different ways.  Below are some ways to sort data.\n",
    "\n",
    "### Sort DataFrame by index\n",
    "Usually, our index is meaningless and starts from zero. However,The index can serve as a sorting mechanism in some cases.\n",
    "\n",
    "You can sort a DataFrame object by index by calling sort_index(). By default, the index is sorted ascending; for descending order, pass ascending=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(4,2), index=[3,1,0,2], columns = ['c1','c2'])\n",
    "print(\"Original DataFrame\")\n",
    "print(df)\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "sorted_df = df.sort_index()\n",
    "print(\" sorted DataFrame(ascending)\" )\n",
    "print(sorted_df)\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "print(\" Sorted DataFrame (descending) \")\n",
    "sorted_df = df.sort_index(ascending=False)\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sort DataFrame by value\n",
    "\n",
    "Sorting is done by sort_values(), which sorts Series by value, and DataFrame by column. The option by is used to specify which columns to use to determine the sort order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\"a\" : [4, 1, 1, 2], \"b\":[1, 4, 2, 6], \"c\":[3,1,6,5]}\n",
    "df = pd.DataFrame(d)\n",
    "print(\"Original DataFrame \")\n",
    "print(df)\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "sorted_df = df.sort_values(by=\"a\")\n",
    "print(\"The  DataFrame is sorted by the column \\\"a\\\"\")\n",
    "print(sorted_df)\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "sorted_df = df.sort_values(by=[\"a\",\"b\"])\n",
    "print(\"The  DataFrame is sorted by the both column \\\"a\\\" and \\\"b\\\"\")\n",
    "print(sorted_df)\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Apply Function to a DataFrame\n",
    "\n",
    "Data Frames can be operated on using the apply() function in Pandas. Let's see how that works.\n",
    "\n",
    "### Use apply function\n",
    "Using apply(), you can pass a function or lambda to a single column, which allows the user to apply the function to each value of the pandas Series and return the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {\"a\": [1,2,3,4],\"b\":[2,3,4,5],\"c\":[3,4,5,6]}\n",
    "df = pd.DataFrame(d)\n",
    "print(\" original DataFrame\")\n",
    "print(df)\n",
    "print(\"--------------------------------------\")\n",
    "df[\"a*2\"] = df[\"a\"].apply(lambda s:s*2)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apply on multiple columns\n",
    "\n",
    "As seen in the last example, pandas is only sending a single column to the function. You need to pass axis=1 if you want to create a column based on two columns; then the entire row will be passed to the function/lambda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {\"a\": [1,2,3,4],\"b\":[2,3,4,5],\"c\":[3,4,5,6]}\n",
    "df = pd.DataFrame(d)\n",
    "print(\" Original DataFrame\")\n",
    "print(df)\n",
    "print(\"--------------------------------------\")\n",
    "df[\"a+b\"] = df.apply(lambda row:row.a + row.b, axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Drop Duplicate Row\n",
    "Data cleaning often involves removing duplicate rows from a dataset. Sometimes the whole row is dropped when it is a duplicate. At other times, we only drop the rows based on selected columns.\n",
    "\n",
    "Drop_duplicates is a powerful and convenient function provided by Pandas. Let's find out how to use it.\n",
    "\n",
    "### Check for duplicate rows in the DataFrame.\n",
    "\n",
    "It may be necessary to determine if a row or only selected columns are duplicated before removing them from the table. The duplicated() function lets you know whether the values of a column are identical or not. You can apply this function to the index, series, and Data Frame\n",
    "\n",
    ". You can find out whether the whole row is duplicated with df.duplicated()\n",
    ". Use df.duplicated(subset=[\"col1\", \"col2\"]) to determine if some selected columns are duplicated\n",
    "\n",
    "### Drop the whole row\n",
    "Using drop_duplicates(), you can simply get rid of duplicate rows based on the whole row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows based on selected columns\n",
    "\n",
    "When using the drop_duplicates function, all the columns will be used to determine whether or not a row is a duplicate. However, you may want to remove rows on specific columns. We can use the option subset to identify duplicate rows by passing the column name\n",
    "\n",
    "\n",
    "If you wish to keep some duplicate rows, the option, (keep) determines which duplicate rows (if any) should be kept :\n",
    "\n",
    "* First: Drops duplicates except for the first.\n",
    "* Last: Drops duplicates except for the last.\n",
    "* False: Drops all duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"col1\": [1, 2, 3, 4, 5],\n",
    "    \"col2\": [\"aa\", \"aa\", \"b\", \"d\", \"d\"],\n",
    "    \"col3\": [1, 1, 5, 4, 3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(\"original DataFrame\")\n",
    "print(df)\n",
    "print(\"----------------------------------\")\n",
    "result = df.drop_duplicates(subset=[\"col2\", \"col3\"], keep=\"last\")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 -Deal With datetime\n",
    "\n",
    "Now let's see how we can deal with datetime in Pandas.\n",
    "\n",
    "Pandas includes extensive features and capabilities for working with time series data, which means it has a lot of features to deal with datetime-related issues\n",
    "\n",
    "### Generate date range\n",
    "\n",
    "Using date_range, a series of dates can be generated whose default frequency is a DAY.\n",
    "\n",
    "The following example generates a series of 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(\"1/1/2020\", periods=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is a table containing the most common abbreviations for frequency.\n",
    "\n",
    "\n",
    "Abbreviation |Meaning \n",
    "-------------|------- \n",
    "D|Day\n",
    "W|week\n",
    "M|month \n",
    "B|work day\n",
    "SM|half month\n",
    "MS| month start\n",
    "Q| end of quarter\n",
    "H| hour\n",
    "T| minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Convert string to timestamp\n",
    "    \n",
    "By calling to_datetime, you can parse a string into a timestamp. The equivalent is calling the timestamp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.to_datetime(\"2020/1/1\")\n",
    "print(ts)\n",
    "ts2 = pd.Timestamp(\"2020/1/1\")\n",
    "print(ts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In above  code, the first line shows how to convert a string into a datetime object by calling to_datetime(). The third line does the same thing, but by utilizing the Timestamp function.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Export Data to File\n",
    "\n",
    "A local file has to be exported in many cases so that data can be stored permanently. Let's explore how data can be exported from memory to local files. Apart from common text-like formats, such as CSV and JSON, it also supports some binary formats, such as pickle and hdf. In this blog we will only cover CSV and Excel. The usage of these formats will be the same as for other formats.\n",
    "\n",
    "\n",
    "\n",
    "### Export data to CSV file \n",
    "\n",
    "A DataFrame is essentially a 2D table, so it makes sense to store the file as a CSV file.\n",
    "To export to a CSV file, simply call to_csv().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"a\": [1, 2, 3, 4], \"b\": [2, 3, 4, 5], \"c\": [3, 4, 5, 6]}\n",
    "df = pd.DataFrame(d)\n",
    "df.to_csv('output/d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are some important options you need to know.\n",
    "\n",
    "* index: The default value is True, which would export the index to the file, too. Even if your original data doesn’t need any index, it still adds the integer index starting from 0. If you don’t need it, just pass index=False.\n",
    "\n",
    "* sep: The default separator is a comma, but you can specify a custom delimiter\n",
    "\n",
    "* float_format: You may want to save some storage because the default floating has a very long floating-point number. float_format='%.2f' rounds to two decimals.\n",
    "\n",
    "* header: The default value is True. If you don’t need the column names, just set header=False.\n",
    "\n",
    "* na_rep: If your data has a missing value, in other words, the data has NA, you can pass a string to represent these missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to an Excel file\n",
    "\n",
    "\n",
    "Exporting Data Frames to an Excel file is slightly different from the CSV file because Excel files support multiple sheets. To write a single DataFrame to an Excel .xlsx file, it is only necessary to specify a file name.\n",
    "In order to write to multiple sheets, you must create an ExcelWriter object with the target file name and a sheet within the file.\n",
    "Meanwhile, to_excel() also supports the index, na_sep, header, and float_format options mentioned above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {\"a\": [1, 2, 3, 4], \"b\": [2, 3, 4, 5], \"c\": [3, 4, 5, 6]}\n",
    "df = pd.DataFrame(d)\n",
    "# The **sheet_name** is optional.\n",
    "df.to_excel(\"output/output.xlsx\", sheet_name='Sheet_name_1')\n",
    "\n",
    "df1 = pd.DataFrame(d)\n",
    "\n",
    "with pd.ExcelWriter('output/output2.xlsx') as writer:  \n",
    "    df.to_excel(writer, sheet_name='Sheet_name_1')\n",
    "    df1.to_excel(writer, sheet_name='Sheet_name_2') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
